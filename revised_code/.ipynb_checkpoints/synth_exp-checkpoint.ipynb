{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376277e4-ae5a-493f-95e9-cff98e7e988b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import standard libraries for data handling and visualization\n",
    "import numpy as np  # Numerical computing\n",
    "import pandas as pd  # Data manipulation\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "from matplotlib.patches import Rectangle  # Used for adding shapes to plots\n",
    "import seaborn as sns  # Statistical visualization\n",
    "\n",
    "# Set seaborn style and font scaling for better visualization aesthetics\n",
    "sns.set(style=\"whitegrid\", font_scale=1.75)\n",
    "\n",
    "# Import scientific computing and machine learning libraries\n",
    "import scipy.special as sp  # Special mathematical functions\n",
    "import sklearn.datasets as datasets  # Example datasets from sklearn\n",
    "import sklearn.linear_model as lm  # Linear models (e.g., logistic regression)\n",
    "import sklearn.ensemble as en  # Ensemble models (e.g., random forests, boosting)\n",
    "import sklearn.tree as tree  # Decision tree models\n",
    "\n",
    "# Import module handling\n",
    "import importlib\n",
    "\n",
    "#### Data generation packages (custom modules)\n",
    "import strawman_edge  # Likely contains functions for generating edge-case datasets\n",
    "import strawman_center  # Likely contains functions for generating center-case datasets\n",
    "import all_linear  # Likely contains functions for generating fully linear datasets\n",
    "import all_nonlinear  # Likely contains functions for generating fully nonlinear datasets\n",
    "\n",
    "#### Main analysis packages\n",
    "import learn_w as learn  # Custom module for learning methods\n",
    "import black  # Code formatter for Python\n",
    "\n",
    "# Reload the `learn` module to apply any recent changes\n",
    "importlib.reload(learn)\n",
    "\n",
    "# Suppress warnings to keep output clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load Jupyter Black extension for auto-formatting Python code in Jupyter Notebook\n",
    "%load_ext jupyter_black\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb4abd-f94c-4cb5-97aa-0b9c40cf3407",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Box DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ad530-354c-49a0-a7eb-3b5107afc16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate synthetic data using the `strawman_edge` module\n",
    "# - `df`: Contains observed covariates and treatment assignments\n",
    "# - `Y`: Contains potential outcomes (Y0, Y1) under different treatments\n",
    "df, Y = strawman_edge.get_data(n=10000, seed=0)\n",
    "\n",
    "# Define key variable names\n",
    "outcome = \"Yobs\"  # Observed outcome variable\n",
    "treatment = \"T\"  # Treatment assignment column (1 = treated, 0 = control)\n",
    "sample = \"S\"  # Sample indicator (used for selection bias analysis)\n",
    "\n",
    "# Compute the true individual treatment effects (ITE)\n",
    "# - TE = Y(1) - Y(0), i.e., the difference between treated and control outcomes\n",
    "TE = Y[\"Y1\"] - Y[\"Y0\"]\n",
    "\n",
    "# Create a deep copy of the original dataset to store the true treatment effect\n",
    "df_true = df.copy(deep=True)\n",
    "df_true[\"TE\"] = TE  # Add true treatment effect to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df909af-1c68-4778-8b56-0a103b6663c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Apply K-means optimization for data partitioning\n",
    "D_labels, f, testing_data = learn.kmeans_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    ")\n",
    "\n",
    "# Assign cluster predictions to df_true\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "\n",
    "# Merge treatment effect (TE), sample indicator (S), and partitioning labels (w)\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "# Compute bias and standard deviation before and after reweighting\n",
    "brute_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "# Repeat similar estimation using Linear Optimization\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "\n",
    "D_labels, f, testing_data = learn.linear_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=42\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "linear_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "# Apply Tree Optimization\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "\n",
    "D_labels, f, testing_data = learn.tree_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=0\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "tree_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "# Apply Forest Optimization\n",
    "importlib.reload(learn)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=1,\n",
    "    num_trees=3000,\n",
    "    vote_threshold=2 / 5,\n",
    ")\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_rash.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "df_refined = df.join(D_w_true[[\"w\"]])\n",
    "df_refined = df_refined.loc[df_refined[\"w\"] == 1]\n",
    "\n",
    "# Estimate DML (Double Machine Learning)\n",
    "np.random.seed(42)\n",
    "df_v, pi, pi_m, e_m, testing_data = learn.estimate_dml(\n",
    "    data=df_refined, outcome=\"Yobs\", treatment=\"T\", sample=\"S\", crossfit=5\n",
    ")\n",
    "\n",
    "forest_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                df_v[\"te\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "# Combine results from different methods and print as LaTeX table\n",
    "print(\n",
    "    pd.concat([forest_box_r, tree_box_r, linear_box_r, brute_box_r], axis=1).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a35957-92f5-44a2-a65e-e937a2802a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload the custom learning module\n",
    "importlib.reload(learn)\n",
    "\n",
    "# Apply Forest Optimization using the `learn.forest_opt` function\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=1,      # Probability threshold for selecting leaf nodes\n",
    "    num_trees=3000,    # Number of trees sampled\n",
    "    vote_threshold=2 / 5, \n",
    ")\n",
    "\n",
    "# Compute the baseline loss (a measure of variance)\n",
    "baseline_loss = np.sqrt(np.sum(D_forest[\"vsq\"]) / ((np.sum((1 - D_forest[\"S\"])) ** 2)))\n",
    "\n",
    "# Plot and save the decision tree visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True, sharey=True, dpi=600)\n",
    "\n",
    "# Visualize the learned decision tree from the forest model\n",
    "tree.plot_tree(\n",
    "    f,\n",
    "    filled=True,  # Color nodes based on majority class\n",
    "    feature_names=df.drop(columns=[outcome, treatment, sample]).columns,  # Exclude treatment and outcome variables\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"explain_box.pdf\", format=\"pdf\", dpi=600)  # Save decision tree visualization\n",
    "\n",
    "# Plot and save scatterplot of `w_opt` (the optimized group assignments)\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "\n",
    "# Scatterplot showing how `w_opt` (partitioning of the data) is assigned across two feature dimensions (X0, X1)\n",
    "sns.scatterplot(\n",
    "    x=\"X0\",\n",
    "    y=\"X1\",\n",
    "    hue=\"w_opt\",\n",
    "    data=D_rash,\n",
    "    ax=ax,\n",
    "    hue_order=[1, 0],  # Control the order of hue categories\n",
    ")\n",
    "\n",
    "# Add a legend for clarity\n",
    "plt.legend(title=\"w\", loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"forest_box.pdf\", format=\"pdf\", dpi=600)  # Save scatterplot visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11119f-caf0-4a1b-88f7-25ce6213147b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Community DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9468939-e2f7-402d-aea3-18e3b5aa595a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(strawman_center)\n",
    "df, Y = strawman_center.get_data(n=5000, seed=0)\n",
    "outcome = \"Yobs\"\n",
    "treatment = \"T\"\n",
    "sample = \"S\"\n",
    "TE = Y[\"Y1\"] - Y[\"Y0\"]\n",
    "df_true = df.copy(deep=True)\n",
    "df_true[\"TE\"] = TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed4033-c107-408b-bcc0-162a3b8d0c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.kmeans_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    ")\n",
    "\n",
    "# D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax)\n",
    "# plt.legend(title=\"w\")\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "brute_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.linear_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=42\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(\n",
    "#     x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax, hue_order={0: \"C1\", 1: \"C2\"}\n",
    "# )\n",
    "# plt.legend(title=\"w\")\n",
    "# # plt.xlim(-0.01, 1.25)\n",
    "# # plt.ylim(-0.01, 1.25)\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "linear_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.tree_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=0\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(\n",
    "#     x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax, hue_order={0: \"C1\", 1: \"C2\"}\n",
    "# )\n",
    "# plt.legend(title=\"w\")\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "tree_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=1,\n",
    "    num_trees=3000,\n",
    "    vote_threshold=1 / 2,\n",
    "    top_k_trees=True,\n",
    "    k=10,\n",
    ")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w_opt\", data=D_rash, ax=ax)\n",
    "# # plt.xlim(-0.01, 1.25)\n",
    "# # plt.ylim(-0.01, 1.25)\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_rash.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "df_refined = df.join(D_w_true[[\"w\"]])\n",
    "df_refined = df_refined.loc[df_refined[\"w\"] == 1]\n",
    "\n",
    "np.random.seed(42)\n",
    "df_v, pi, pi_m, e_m, testing_data = learn.estimate_dml(\n",
    "    data=df_refined, outcome=\"Yobs\", treatment=\"T\", sample=\"S\", crossfit=5\n",
    ")\n",
    "\n",
    "forest_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                df_v[\"te\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    pd.concat([forest_box_r, tree_box_r, linear_box_r, brute_box_r], axis=1).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667382a0-9968-48ce-95ae-61e56a1720af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=1,\n",
    "    num_trees=3000,\n",
    "    vote_threshold=1 / 2,\n",
    ")\n",
    "baseline_loss = np.sqrt(np.sum(D_forest[\"vsq\"]) / ((np.sum((1 - D_forest[\"S\"])) ** 2)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True, sharey=True, dpi=600)\n",
    "tree.plot_tree(\n",
    "    f,\n",
    "    filled=True,\n",
    "    feature_names=df.drop(columns=[outcome, treatment, sample]).columns,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"explain_community.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"S\", data=df, ax=ax, palette=\"Set1\", legend=False)\n",
    "sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w_opt\", data=D_rash, ax=ax, hue_order=[1, 0])\n",
    "# plt.legend(title=\"w\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"forest_community.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"S\", data=df, ax=ax, palette=\"Set1\", legend=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdea862-7d3e-4527-a14d-25cf674cb698",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Highdimensional Linear DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc453212-1c3b-4959-956e-7911ca71854b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(all_linear)\n",
    "df, Y, coef = all_linear.get_data(n=5000, seed=1)\n",
    "outcome = \"Yobs\"\n",
    "treatment = \"T\"\n",
    "sample = \"S\"\n",
    "TE = Y[\"Y1\"] - Y[\"Y0\"]\n",
    "df_true = df.copy(deep=True)\n",
    "df_true[\"TE\"] = TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee15c2-4f29-4551-9557-4f60ef4aa8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.kmeans_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    ")\n",
    "\n",
    "# D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax)\n",
    "# plt.legend(title=\"w\")\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "brute_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.linear_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=42\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(\n",
    "#     x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax, hue_order={0: \"C1\", 1: \"C2\"}\n",
    "# )\n",
    "# plt.legend(title=\"w\")\n",
    "# # plt.xlim(-0.01, 1.25)\n",
    "# # plt.ylim(-0.01, 1.25)\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "linear_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_labels, f, testing_data = learn.tree_opt(\n",
    "    data=df, outcome=outcome, treatment=treatment, sample=sample, seed=0\n",
    ")\n",
    "\n",
    "D_labels[\"w\"] = D_labels[\"w\"].astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(\n",
    "#     x=\"X0\", y=\"X1\", hue=\"w\", data=D_labels, ax=ax, hue_order={0: \"C1\", 1: \"C2\"}\n",
    "# )\n",
    "# plt.legend(title=\"w\")\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_labels.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "\n",
    "tree_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"v\"\n",
    "                ].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w_true\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=0.5,\n",
    "    num_trees=2000,\n",
    "    vote_threshold=2 / 3,\n",
    "    top_k_trees=True,\n",
    "    k=20,\n",
    ")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "# sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w_opt\", data=D_rash, ax=ax)\n",
    "# # plt.xlim(-0.01, 1.25)\n",
    "# # plt.ylim(-0.01, 1.25)\n",
    "# plt.legend(ncols=2, loc=\"lower left\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_rash.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "df_refined = df.join(D_w_true[[\"w\"]])\n",
    "df_refined = df_refined.loc[df_refined[\"w\"] == 1]\n",
    "\n",
    "np.random.seed(42)\n",
    "df_v, pi, pi_m, e_m, testing_data = learn.estimate_dml(\n",
    "    data=df_refined, outcome=\"Yobs\", treatment=\"T\", sample=\"S\", crossfit=5\n",
    ")\n",
    "\n",
    "forest_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                df_v[\"te\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    pd.concat([forest_box_r, tree_box_r, linear_box_r, brute_box_r], axis=1).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6c30e-2cba-4631-85c4-ce8f4042d4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=1,\n",
    "    num_trees=3000,\n",
    "    vote_threshold=4 / 5,\n",
    "    top_k_trees=True,\n",
    "    k=10,\n",
    ")\n",
    "baseline_loss = np.sqrt(np.sum(D_forest[\"vsq\"]) / ((np.sum((1 - D_forest[\"S\"])) ** 2)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True, sharey=True, dpi=600)\n",
    "tree.plot_tree(\n",
    "    f,\n",
    "    filled=True,\n",
    "    feature_names=df.drop(columns=[outcome, treatment, sample]).columns,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"explain_linear.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(x=\"X2\", y=\"X7\", hue=\"w_opt\", data=D_rash, ax=ax, hue_order=[1, 0])\n",
    "plt.legend(title=\"w\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"forest_linear.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(\n",
    "    x=\"X2\",\n",
    "    y=\"X7\",\n",
    "    hue=\"S\",\n",
    "    data=df,\n",
    "    ax=ax,\n",
    "    palette=\"Set1\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdb4bf-89fc-4b71-a5fb-6e7af0a1621e",
   "metadata": {},
   "source": [
    "# Nonlinear DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be984d37-caa2-4745-909f-fdf38dfe4b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import all_nonlinear\n",
    "\n",
    "importlib.reload(all_nonlinear)\n",
    "df, Y, coef = all_nonlinear.get_data_nonlinear(n=10000, seed=1)\n",
    "outcome = \"Yobs\"\n",
    "treatment = \"T\"\n",
    "sample = \"S\"\n",
    "TE = Y[\"Y1\"] - Y[\"Y0\"]\n",
    "df_true = df.copy(deep=True)\n",
    "df_true[\"TE\"] = TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d7a24-ed6f-4f06-bd36-0c5083e61a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"S\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bf772-045d-4a21-9b5b-33c68805308b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(learn)\n",
    "np.random.seed(42)\n",
    "D_rash, D_forest, w_forest, rashomon_set, f, testing_data = learn.forest_opt(\n",
    "    data=df,\n",
    "    outcome=outcome,\n",
    "    treatment=treatment,\n",
    "    sample=sample,\n",
    "    leaf_proba=0.5,\n",
    "    num_trees=2000,\n",
    "    vote_threshold=2 / 3,\n",
    "    top_k_trees=True,\n",
    "    k=20,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(x=\"X0\", y=\"X1\", hue=\"w_opt\", data=D_rash, ax=ax)\n",
    "# plt.xlim(-0.01, 1.25)\n",
    "# plt.ylim(-0.01, 1.25)\n",
    "plt.legend(ncols=2, loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "df_true[\"w\"] = f.predict(df_true[[col for col in df_true.columns if \"X\" in col]])\n",
    "D_w_true = D_rash.join(df_true[[\"TE\", \"S\", \"w\"]], rsuffix=\"_true\", how=\"outer\")\n",
    "df_refined = df.join(D_w_true[[\"w\"]])\n",
    "df_refined = df_refined.loc[df_refined[\"w\"] == 1]\n",
    "\n",
    "np.random.seed(42)\n",
    "df_v, pi, pi_m, e_m, testing_data = learn.estimate_dml(\n",
    "    data=df_refined, outcome=\"Yobs\", treatment=\"T\", sample=\"S\", crossfit=5\n",
    ")\n",
    "\n",
    "forest_box_r = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            (\n",
    "                D_w_true.loc[(D_w_true[\"S_true\"] == 1)][\"v\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0)][\"TE\"].mean()\n",
    "            ),\n",
    "            (\n",
    "                df_v[\"te\"].mean()\n",
    "                - D_w_true.loc[(D_w_true[\"S_true\"] == 0) * (D_w_true[\"w\"] == 1)][\n",
    "                    \"TE\"\n",
    "                ].mean()\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            np.sqrt(\n",
    "                D_w_true.loc[(D_w_true[\"S\"] == 1)][\"vsq\"].sum()\n",
    "                / (D_w_true.loc[(D_w_true[\"S\"] == 1)].shape[0]) ** 2\n",
    "            ),\n",
    "            (\n",
    "                np.sqrt(\n",
    "                    D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)][\n",
    "                        \"vsq\"\n",
    "                    ].sum()\n",
    "                    / (\n",
    "                        D_w_true.loc[(D_w_true[\"S\"] == 1) * (D_w_true[\"w\"] == 1)].shape[\n",
    "                            0\n",
    "                        ]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    ],\n",
    "    index=[\"Bias\", \"Stdev\"],\n",
    "    columns=[\"Pre\", \"Post\"],\n",
    ")\n",
    "\n",
    "# print(\n",
    "#     pd.concat([forest_box_r, tree_box_r, linear_box_r, brute_box_r], axis=1).to_latex()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f19dd-0be1-4d19-8786-6f194a32928a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_loss = np.sqrt(np.sum(D_forest[\"vsq\"]) / ((np.sum((1 - D_forest[\"S\"])) ** 2)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True, sharey=True, dpi=600)\n",
    "tree.plot_tree(\n",
    "    f,\n",
    "    filled=True,\n",
    "    feature_names=df.drop(columns=[outcome, treatment, sample]).columns,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"explain_nonlinear.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(x=\"X2\", y=\"X7\", hue=\"w_opt\", data=D_rash, ax=ax, hue_order=[1, 0])\n",
    "plt.legend(title=\"w\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"forest_nonlinear.pdf\", format=\"pdf\", dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True, dpi=600)\n",
    "sns.scatterplot(\n",
    "    x=\"X2\",\n",
    "    y=\"X7\",\n",
    "    hue=\"S\",\n",
    "    data=df,\n",
    "    ax=ax,\n",
    "    palette=\"Set1\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58359a06-4705-4a23-8a7e-89dc92b9aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
